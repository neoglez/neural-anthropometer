{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neoglez/neural-anthropometer/blob/main/notebook/train_neural_antropomter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone and install Neural-Anthropometer"
      ],
      "metadata": {
        "id": "n7WljTp_lp7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HBM, Vedo and Trimesh"
      ],
      "metadata": {
        "id": "telyuLR6lye1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /home\n",
        "!rm -rf computational_intelligence || true\n",
        "!mkdir computational_intelligence\n",
        "!ls\n",
        "%cd computational_intelligence"
      ],
      "metadata": {
        "id": "zaKUCEcxL_jy",
        "outputId": "99993323-58ca-4c01-8600-fa1c9ed95329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home\n",
            "computational_intelligence\n",
            "/home/computational_intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BPube3pevfx8",
        "outputId": "ce4bfe1e-3060-4fc1-b1dd-4ee15ceffc48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hbm'...\n",
            "warning: redirecting to https://github.com/neoglez/hbm.git/\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 43 (delta 14), reused 32 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (43/43), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone http://github.com/neoglez/hbm.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hbm\n",
        "\n",
        "!pip install .\n",
        "\n",
        "!conda install -c conda-forge vedo\n",
        "\n",
        "!pip install trimesh sklearn matplotlib"
      ],
      "metadata": {
        "id": "BWWyAeH-wSEH",
        "outputId": "aced441d-a049-42bb-a336-76701e2ff6c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/computational_intelligence/hbm\n",
            "Processing /home/computational_intelligence/hbm\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hbm==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from hbm==0.0.1) (4.1.2.30)\n",
            "Building wheels for collected packages: hbm\n",
            "  Building wheel for hbm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hbm: filename=hbm-0.0.1-py3-none-any.whl size=12044 sha256=81f84ccf48125eb1e42259bf719e6cf17b8e5a2662ae12ae69f68c4aa65c5baf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-71bkwmtp/wheels/e8/9b/32/38b51e728edcfcc0e3689b4a9c9329b5074102fe6602f64cd4\n",
            "Successfully built hbm\n",
            "Installing collected packages: hbm\n",
            "Successfully installed hbm-0.0.1\n",
            "/bin/bash: conda: command not found\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-3.9.39-py3-none-any.whl (640 kB)\n",
            "\u001b[K     |████████████████████████████████| 640 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trimesh) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Installing collected packages: trimesh\n",
            "Successfully installed trimesh-3.9.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Neural-Anthropometer"
      ],
      "metadata": {
        "id": "VQJUDi7El8Pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "b6E7wxfql--o",
        "outputId": "ab49570b-2790-492b-e306-8cf7dec43271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/computational_intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone http://github.com/neoglez/neural-anthropometer.git\n",
        "%cd neural-anthropometer\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "JLuyTunWmKMv",
        "outputId": "9ce3e036-0f1f-4bb5-a4fb-84e379c522fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neural-anthropometer'...\n",
            "warning: redirecting to https://github.com/neoglez/neural-anthropometer.git/\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
            "remote: Total 245 (delta 109), reused 115 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (245/245), 551.13 KiB | 14.89 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "/home/computational_intelligence/neural-anthropometer\n",
            "Processing /home/computational_intelligence/neural-anthropometer\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from neural-anthropometer==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from neural-anthropometer==0.0.1) (4.1.2.30)\n",
            "Building wheels for collected packages: neural-anthropometer\n",
            "  Building wheel for neural-anthropometer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neural-anthropometer: filename=neural_anthropometer-0.0.1-py3-none-any.whl size=34840 sha256=1965284941d5be4f12eecbc593f63db270d74cfc0992bb98694a3fcac20d945b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/a9/e6/d57aa8c5734fa981a36c48bec89373240cbb4d7b912634f5d9\n",
            "Successfully built neural-anthropometer\n",
            "Installing collected packages: neural-anthropometer\n",
            "Successfully installed neural-anthropometer-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Neural-Anthropometer dataset"
      ],
      "metadata": {
        "id": "GPUFLCFXme1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /home\n",
        "!rm -rf Downloads || true\n",
        "!mkdir Downloads\n",
        "!ls\n",
        "%cd Downloads"
      ],
      "metadata": {
        "id": "DI43aH64y1s2",
        "outputId": "71bb137c-6dd3-47fc-9abb-3aa3edc979e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home\n",
            "computational_intelligence  Downloads\n",
            "/home/Downloads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from requests.sessions import default_headers\n",
        "import requests\n",
        "import urllib\n",
        "import re\n",
        "\n",
        "url = \"https://cloudlogin03.world4you.com/index.php/s/5uD3bt1n207k8ko/authenticate\"\n",
        "download_url = \"https://cloudlogin03.world4you.com/index.php/s/5uD3bt1n207k8ko/download\"\n",
        "password = \"na-dataset\"\n",
        "requesttoken = ''\n",
        "\n",
        "\n",
        "s = requests.Session()\n",
        "r0 = s.get(url)\n",
        "\n",
        "requesttoken = re.findall('(?<=data-requesttoken=\").*?(?=\">)', r0.text)\n",
        "if (requesttoken):\n",
        "  requesttoken = requesttoken[0]\n",
        "print(requesttoken)\n",
        "\n",
        "data = {'requesttoken': requesttoken, 'password': password}\n",
        "r1 = s.post(url, data=data)\n",
        "\n",
        "print(\"Downloding Neural Anthropometer Dataset\")\n",
        "r2 = s.get(download_url, stream=True)\n",
        "total_size_in_bytes= int(r2.headers.get('content-length', 0))\n",
        "block_size = 1024 #1 Kilobyte\n",
        "progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
        "with open('neural-anthropometer.tar.gz', 'wb') as file:\n",
        "    for data in r2.iter_content(block_size):\n",
        "        progress_bar.update(len(data))\n",
        "        file.write(data)\n",
        "progress_bar.close()\n",
        "if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
        "    print(\"ERROR, something went wrong\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bG4x7dX35kEX",
        "outputId": "1bb1b62f-fe3b-4360-e041-df17ed024192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KkoNNDJNPS02NTQAIy9AJAU1MigoeTIRGn5UPAgKdh8=:hxjRk8qzdQmTlNubkOQEX0VA+OlSmxAvs0BuYdHtgvo=\n",
            "Downloding Neural Anthropometer Dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.02G/2.02G [01:00<00:00, 33.3MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "import os\n",
        "def convert_bytes(num):\n",
        "    \"\"\"\n",
        "    this function will convert bytes to MB.... GB... etc\n",
        "    \"\"\"\n",
        "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
        "        if num < 1024.0:\n",
        "            return \"%3.1f %s\" % (num, x)\n",
        "        num /= 1024.0\n",
        "\n",
        "\n",
        "def file_size(file_path):\n",
        "    \"\"\"\n",
        "    this function will return the file size\n",
        "    \"\"\"\n",
        "    if os.path.isfile(file_path):\n",
        "        file_info = os.stat(file_path)\n",
        "        return convert_bytes(file_info.st_size)\n",
        "\n",
        "\n",
        "# Lets check the file size of MS Paint exe \n",
        "# or you can use any file path\n",
        "file_path = \"../../Downloads/neural-anthropometer.tar.gz\"\n",
        "print(file_size(file_path))"
      ],
      "metadata": {
        "id": "LXo7I6IM2-C7",
        "outputId": "2c931d73-10fd-4f31-c296-af111ad6e6bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neural-anthropometer.tar.gz\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../../Downloads\n",
        "!tar -xf neural-anthropometer.tar.gz\n",
        "!mv dataset/*  /home/computational_intelligence/neural-anthropometer/dataset/"
      ],
      "metadata": {
        "id": "fgaCHLwC0s0J",
        "outputId": "c4261edc-ff2d-4c1c-d416-b6bea0346eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '../../Downloads'\n",
            "/home/Downloads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf neural-anthropometer.tar.gz"
      ],
      "metadata": {
        "id": "T1mke4KVN_B_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf dataset"
      ],
      "metadata": {
        "id": "RwkdF0L01Ngs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and evaluating The Neural Anthropometer"
      ],
      "metadata": {
        "id": "JvZf5PHXQCxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation"
      ],
      "metadata": {
        "id": "oysnS5dVQPcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "metadata": {
        "id": "KVS9LW600385",
        "outputId": "4ef86007-ce4d-4b5a-f1cc-e7c38c9a94e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /home/computational_intelligence/neural-anthropometer"
      ],
      "metadata": {
        "id": "jFpSVG0DYHbK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is the content of the file `experiments/experiment_1_input_all_test_all_save_results.py` adapted to work in this colab\n",
        "\n"
      ],
      "metadata": {
        "id": "zxLwdqpJwlR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "H3rfhL3-SUYh",
        "outputId": "ba3324bc-fdb7-49d7-d9aa-60fd7e36d3b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------\n",
            "absl-py                       0.12.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.1.0\n",
            "appdirs                       1.4.4\n",
            "argcomplete                   1.12.3\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.11.4\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.2.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.3\n",
            "Babel                         2.9.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        4.1.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.2\n",
            "branca                        0.4.2\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.10\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.10.8\n",
            "cffi                          1.15.0\n",
            "cftime                        1.5.1.1\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.9\n",
            "click                         7.1.2\n",
            "cloudpickle                   1.3.0\n",
            "cmake                         3.12.0\n",
            "cmdstanpy                     0.9.5\n",
            "colorcet                      2.0.6\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.3.2\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda111                  9.4.0\n",
            "cvxopt                        1.2.7\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.6\n",
            "Cython                        0.29.24\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.4\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.6\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.290\n",
            "easydict                      1.9\n",
            "ecos                          2.0.7.post1\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.3\n",
            "ephem                         4.1\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastdtw                       0.3.4\n",
            "fastprogress                  1.0.0\n",
            "fastrlock                     0.8\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.4.0\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   2.0\n",
            "folium                        0.8.3\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         3.6.4\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.26.3\n",
            "google-api-python-client      1.12.8\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.0\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.53.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.2\n",
            "grpcio                        1.42.0\n",
            "gspread                       3.0.1\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "hbm                           0.0.1\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.2\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.6\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.3.0\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.8.2\n",
            "importlib-resources           5.4.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2021.4.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.6.5\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.2.25\n",
            "jaxlib                        0.1.71+cuda111\n",
            "jdcal                         1.4.1\n",
            "jedi                          0.18.1\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.1.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    2.6.0\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.9.1\n",
            "jupyterlab-pygments           0.1.2\n",
            "jupyterlab-widgets            1.0.2\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.6\n",
            "keras                         2.7.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.3.2\n",
            "korean-lunar-calendar         0.2.1\n",
            "libclang                      12.0.0\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.6\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-inline             0.1.3\n",
            "matplotlib-venn               0.11.6\n",
            "missingno                     0.5.0\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.12.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.3\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.10\n",
            "murmurhash                    1.0.6\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.5.9\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.1.3\n",
            "nest-asyncio                  1.5.4\n",
            "netCDF4                       1.5.8\n",
            "networkx                      2.6.3\n",
            "neural-anthropometer          0.0.1\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.7.3\n",
            "numpy                         1.19.5\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.1.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "openpyxl                      2.5.9\n",
            "opt-einsum                    3.3.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.1.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.0\n",
            "parso                         0.8.3\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.2\n",
            "pep517                        0.12.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        4.4.1\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.5.2\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.6\n",
            "prettytable                   2.4.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.12.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "protobuf                      3.17.3\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "pyarrow                       3.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.3\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.2.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.1\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.5\n",
            "pyparsing                     3.0.6\n",
            "pyrsistent                    0.18.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.15\n",
            "python-slugify                5.0.2\n",
            "python-utils                  2.5.6\n",
            "pytz                          2018.9\n",
            "pyviz-comms                   2.1.0\n",
            "PyWavelets                    1.2.0\n",
            "PyYAML                        3.13\n",
            "pyzmq                         22.3.0\n",
            "qdldl                         0.1.5.post0\n",
            "qtconsole                     5.2.2\n",
            "QtPy                          2.0.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.23.0\n",
            "requests-oauthlib             1.3.0\n",
            "resampy                       0.2.2\n",
            "retrying                      1.3.3\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.8\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.1\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           2.1.4\n",
            "seaborn                       0.11.2\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.0\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.27\n",
            "sqlparse                      0.4.2\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.4.4\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tensorboard                   2.7.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.0\n",
            "tensorflow                    2.7.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.7.0\n",
            "tensorflow-gcs-config         2.7.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.22.0\n",
            "tensorflow-metadata           1.4.0\n",
            "tensorflow-probability        0.15.0\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.12.1\n",
            "testpath                      0.5.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "threadpoolctl                 3.0.0\n",
            "tifffile                      2021.11.2\n",
            "toml                          0.10.2\n",
            "tomli                         1.2.2\n",
            "toolz                         0.11.2\n",
            "torch                         1.10.0+cu111\n",
            "torchaudio                    0.10.0+cu111\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.11.0\n",
            "torchvision                   0.11.1+cu111\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.62.3\n",
            "traitlets                     5.1.1\n",
            "trimesh                       3.9.39\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             3.10.0.2\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.8.2\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.0\n",
            "widgetsnbextension            3.5.2\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.13.3\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.3.post1\n",
            "zict                          2.0.0\n",
            "zipp                          3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vedo\n",
        "import neural_anthropometer as na"
      ],
      "metadata": {
        "id": "yQLzPTi-SOt5",
        "outputId": "42eddd1a-b0b2-4e93-d196-af34ac4563f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vedo\n",
            "  Downloading vedo-2021.0.7.tar.gz (19.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.0 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting vtk<9.1.0\n",
            "  Downloading vtk-9.0.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (59.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.5 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vedo) (1.19.5)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from vtk<9.1.0->vedo) (3.2.2)\n",
            "Collecting autobahn>=17.7.1\n",
            "  Downloading autobahn-21.11.1.tar.gz (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting Twisted>=17.5.0\n",
            "  Downloading Twisted-21.7.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 40.5 MB/s \n",
            "\u001b[?25hCollecting wslink>=0.1.3\n",
            "  Downloading wslink-1.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting txaio>=21.2.1\n",
            "  Downloading txaio-21.2.1-py2.py3-none-any.whl (30 kB)\n",
            "Collecting cryptography>=3.4.6\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 45.3 MB/s \n",
            "\u001b[?25hCollecting hyperlink>=21.0.0\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from autobahn>=17.7.1->vtk<9.1.0->vedo) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.4.6->autobahn>=17.7.1->vtk<9.1.0->vedo) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.4.6->autobahn>=17.7.1->vtk<9.1.0->vedo) (2.21)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=21.0.0->autobahn>=17.7.1->vtk<9.1.0->vedo) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk<9.1.0->vedo) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk<9.1.0->vedo) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk<9.1.0->vedo) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk<9.1.0->vedo) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->vtk<9.1.0->vedo) (1.15.0)\n",
            "Collecting incremental>=21.3.0\n",
            "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting zope.interface>=4.4.2\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.5.0->vtk<9.1.0->vedo) (21.2.0)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.5.0->vtk<9.1.0->vedo) (3.10.0.2)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->wslink>=0.1.3->vtk<9.1.0->vedo) (2.0.9)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 53.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->vedo) (1.13.3)\n",
            "Building wheels for collected packages: vedo, autobahn\n",
            "  Building wheel for vedo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vedo: filename=vedo-2021.0.7-py3-none-any.whl size=19111429 sha256=d86a3374d25f5554e4e553fc8705fb2d293a2f02ccc852ee3e351501f48c53b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/c0/be/f023321735be793a5fa2f540835b2aae47a3016ef4bfd7126a\n",
            "  Building wheel for autobahn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autobahn: filename=autobahn-21.11.1-cp37-cp37m-linux_x86_64.whl size=537832 sha256=db59b086de7d18915235e93501711bf645205339ecef3f761c776b4d52822eb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/ec/a5/d64c91164433c5128635f83e59f631e088dda71f14e030056e\n",
            "Successfully built vedo autobahn\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, zope.interface, txaio, incremental, hyperlink, cryptography, constantly, Automat, aiohttp, wslink, Twisted, autobahn, vtk, Deprecated, vedo\n",
            "Successfully installed Automat-20.2.0 Deprecated-1.2.13 Twisted-21.7.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 autobahn-21.11.1 constantly-15.1.0 cryptography-36.0.1 frozenlist-1.2.0 hyperlink-21.0.0 incremental-21.3.0 multidict-5.2.0 txaio-21.2.1 vedo-2021.0.7 vtk-9.0.3 wslink-1.3.1 yarl-1.7.2 zope.interface-5.4.0\n",
            "embedWindow(verbose=True): could not load ipyvtklink try:\n",
            "> pip install ipyvtklink\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import neural_anthropometer as na\n",
        "import numpy as np\n",
        "import datetime\n",
        "from sklearn.model_selection import KFold\n",
        "import locale\n",
        "\n",
        "locale.setlocale(locale.LC_NUMERIC, \"C\")\n",
        "\n",
        "rootDir = \"/home/computational_intelligence/neural-anthropometer/dataset\"\n",
        "print(rootDir)\n",
        "\n",
        "\n",
        "model_path = os.path.join(rootDir, \"..\", \"model\")\n",
        "kfold_results_path = os.path.join(rootDir, \"..\", \"results\")\n",
        "kfold_results_path = os.path.join(kfold_results_path, \"experiment1\")\n",
        "kfold_results_numpy_name = \"kfold_results.npy\"\n",
        "results_file = os.path.join(kfold_results_path, kfold_results_numpy_name)\n",
        "\n",
        "kfold_results_info_name = \"results_info.svg\"\n",
        "kfold_results_info_name = \"kfold_info.svg\"\n",
        "\n",
        "# Configuration options\n",
        "k_folds = 5\n",
        "batch_size = 100\n",
        "num_epochs = 20\n",
        "# CUDA for PyTorch\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(41)\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# For fold results\n",
        "results = {}\n",
        "\n",
        "# loss and optimizer\n",
        "# Note that the loss here is a scalar because reduction=\"mean\",\n",
        "# therefore, after subtracting element-wise the dimensions\n",
        "# predicted - actuals, every element of the resulting tensor is squared.\n",
        "# Finally, the tensor is flatten, the elements are summed and the sum is\n",
        "# divided by the number of elements in the tensor.\n",
        "# That means for us that we are going to train based on the mean squared error\n",
        "# (squared L2 norm).\n",
        "transform = na.TwoDToTensor()\n",
        "criterion = nn.MSELoss()\n",
        "# performance_criterion = nn.MSELoss(reduction=\"none\")\n",
        "error_criterion = nn.MSELoss()\n",
        "\n",
        "lr = 0.01\n",
        "momentum = 0.9\n",
        "\n",
        "dataset = na.NeuralAnthropometerSyntheticImagesDataset(\n",
        "    root_dir=rootDir, transform=transform\n",
        ")\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "model_timestamp = datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "\n",
        "# Here we collect the results: we are going to record the estimated and\n",
        "# and actual measurements over the 5 folds. In this step, we do not\n",
        "# calculate error, loss or any other statistic. We merely save the data to\n",
        "# analyze it later. Since we have 5 folds, and 8 HBD estimated and actuals,\n",
        "# we must have at the end a tensor of size 5 X 8 X 2.\n",
        "results = np.zeros((k_folds,\n",
        "                    int(len(dataset)/ k_folds),\n",
        "                    2,\n",
        "                    8))\n",
        "\n",
        "# Start print\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "    # Print\n",
        "    print(f\"FOLD {fold}\")\n",
        "    print(\"--------------------------------\")\n",
        "\n",
        "    # Sample elements randomly from a given list of ids, no replacement.\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "    # Define data loaders for training and testing data in this fold\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, sampler=train_subsampler\n",
        "    )\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=1, sampler=test_subsampler\n",
        "    )\n",
        "\n",
        "    # Init the neural network\n",
        "    network = na.NeuralAnthropometer(debug=False).to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = optim.SGD(network.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # Run the training loop for defined number of epochs\n",
        "    for epoch in range(0, num_epochs):\n",
        "\n",
        "        # Print epoch\n",
        "        print(f\"Starting epoch {epoch+1}\")\n",
        "\n",
        "        # Set current loss value\n",
        "        current_loss = 0.0\n",
        "\n",
        "        # Iterate over the DataLoader for training data\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # Get inputs\n",
        "            # move to GPU if available\n",
        "            targets = data[\"annotations\"][\"human_dimensions\"].to(device)\n",
        "            inputs = data[\"image\"].to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Perform forward pass\n",
        "            outputs = network(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Perform backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Perform optimization\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print statistics\n",
        "            current_loss += loss.item()\n",
        "            if i % 25 == 24:\n",
        "                print(\n",
        "                    \"Loss after mini-batch %5d: %.5f\"\n",
        "                    % (i + 1, current_loss / 25)\n",
        "                )\n",
        "                current_loss = 0.0\n",
        "\n",
        "    # Process is complete.\n",
        "    print(\"Training process has finished. Saving trained model.\")\n",
        "\n",
        "    # Saving the model\n",
        "    model_name = (\n",
        "        \"Neural_Anthropometer_Model_\"\n",
        "        + model_timestamp\n",
        "        + \"_fold-{}.pt\".format(fold)\n",
        "    )\n",
        "    model_file = os.path.join(model_path, model_name)\n",
        "    torch.save(network.state_dict(), model_file)\n",
        "\n",
        "    # Evaluation for this fold\n",
        "    kfold_this_error = 0\n",
        "    with torch.no_grad():\n",
        "        # Iterate over the test data and generate predictions\n",
        "        for i, data in enumerate(testloader, 0):\n",
        "\n",
        "            # Get inputs\n",
        "            targets = data[\"annotations\"][\"human_dimensions\"].to(device)\n",
        "            inputs = data[\"image\"].to(device)\n",
        "\n",
        "            # Generate outputs\n",
        "            outputs = network(inputs)\n",
        "\n",
        "            # record for this fold estimated and actuals\n",
        "            # first the estimated\n",
        "            results[fold][i][0] = outputs.detach().cpu().numpy().T.flatten()\n",
        "            # second the actuals\n",
        "            results[fold][i][1] = targets.detach().cpu().numpy().T.flatten()\n",
        "\n",
        "        # Average error for this fold\n",
        "        kfold_performace_error = kfold_this_error / len(testloader)\n",
        "        # Print accuracy. In our case MSE over all dimensions.\n",
        "        # The smaller, the better. Note that we have to average the MSE across\n",
        "        # the mini-batches.\n",
        "        print(\"Estimated and actual recorded for fold {:d}\".format(fold))\n",
        "        print(\"--------------------------------\")\n",
        "\n",
        "# Print fold results\n",
        "print(f\"K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS RECORDED\")\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "# save results in numpy format\n",
        "with open(results_file, \"wb\") as f:\n",
        "    np.save(f, results)"
      ],
      "metadata": {
        "id": "bNrSdv_ISBtH",
        "outputId": "d9896d06-096f-40a0-f7c9-a4825a060834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/computational_intelligence/neural-anthropometer/dataset\n",
            "--------------------------------\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Starting epoch 1\n",
            "Loss after mini-batch    25: 0.14672\n",
            "Loss after mini-batch    50: 0.00851\n",
            "Loss after mini-batch    75: 0.00345\n",
            "Starting epoch 2\n",
            "Loss after mini-batch    25: 0.00161\n",
            "Loss after mini-batch    50: 0.00129\n",
            "Loss after mini-batch    75: 0.00111\n",
            "Starting epoch 3\n",
            "Loss after mini-batch    25: 0.00090\n",
            "Loss after mini-batch    50: 0.00089\n",
            "Loss after mini-batch    75: 0.00079\n",
            "Starting epoch 4\n",
            "Loss after mini-batch    25: 0.00070\n",
            "Loss after mini-batch    50: 0.00071\n",
            "Loss after mini-batch    75: 0.00065\n",
            "Starting epoch 5\n",
            "Loss after mini-batch    25: 0.00060\n",
            "Loss after mini-batch    50: 0.00058\n",
            "Loss after mini-batch    75: 0.00055\n",
            "Starting epoch 6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-22d5fa1df5f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# Print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 print(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "train_neural_antropomter.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}